{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b5ad49",
   "metadata": {},
   "source": [
    "# Hướng dẫn hoàn chỉnh về PySpark và SparkSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf57217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chúng tôi sử dụng thư viện findspark để xác định vị trí spark trên máy cục bộ của chúng\n",
    "import findspark\n",
    "findspark.init('C:/spark/spark/spark-3.2.3-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8071fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0a602",
   "metadata": {},
   "source": [
    "# 1. Khởi tạo phiên Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18bca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x0000028992D2FFD0>\n"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName(\"PysparkExample\").config (\"spark.sql.shuffle.partitions\",\"50\").config(\"spark.driver.maxResultSize\",\"5g\").config(\"spark.sql.execution.arrow.enabled\", \"true\").getOrCreate()\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0301dd",
   "metadata": {},
   "source": [
    "# SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d8db8",
   "metadata": {},
   "source": [
    "<p><a href=\"http://172.16.2.39:4040\">Spark UI</a></p>\n",
    "<dl>\n",
    "<dt>Version</dt>\n",
    "<dd><code>v3.2.3</code></dd>\n",
    "<dt>Master</dt>\n",
    "<dd><code>local[*]</code></dd>\n",
    "<dt>AppName</dt>\n",
    "<dd><code>PysparkExample</code></dd>\n",
    "</dl>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fda0f",
   "metadata": {},
   "source": [
    "# 2. Tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d242dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON\n",
    "dataframe = sc.read.json('C:/data/nyt2.json')\n",
    "# dataframe_txt = sc.read.text('./data/text_data.txt')\n",
    "#CSV files\n",
    "# dataframe_csv = sc.read.csv('./data/csv_data.csv')\n",
    "#PARQUET files\n",
    "# dataframe_parquet = sc.read.load('./data/parquet_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d21704",
   "metadata": {},
   "source": [
    "# Xemdữ liệu với show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b5a9a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+\n",
      "|                 _id|  amazon_product_url|              author| bestsellers_date|         description|        price|   published_date|    publisher|rank|rank_last_week|               title|weeks_on_list|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {null, 27}|{{1212883200000}}|       Bantam| {1}|           {0}|           ODD HOURS|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}|{{1212883200000}}|Little, Brown| {2}|           {1}|            THE HOST|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|        Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}|{{1212883200000}}| St. Martin's| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|   Patricia Cornwell|{{1211587200000}}|A Massachusetts s...|{22.95, null}|{{1212883200000}}|       Putnam| {4}|           {0}|           THE FRONT|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Chuck Palahniuk|{{1211587200000}}|An aging porn que...|{24.95, null}|{{1212883200000}}|    Doubleday| {5}|           {0}|               SNUFF|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|James Patterson a...|{{1211587200000}}|A woman finds an ...|{24.99, null}|{{1212883200000}}|Little, Brown| {6}|           {3}|SUNDAYS AT TIFFANY’S|          {4}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       John Sandford|{{1211587200000}}|The Minneapolis d...|{26.95, null}|{{1212883200000}}|       Putnam| {7}|           {4}|        PHANTOM PREY|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       Jimmy Buffett|{{1211587200000}}|A Southern family...|{21.99, null}|{{1212883200000}}|Little, Brown| {8}|           {6}|          SWINE NOT?|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    Elizabeth George|{{1211587200000}}|In Cornwall, tryi...|{27.95, null}|{{1212883200000}}|       Harper| {9}|           {8}|     CARELESS IN RED|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|      David Baldacci|{{1211587200000}}|An intelligence a...|{26.99, null}|{{1212883200000}}|Grand Central|{10}|           {7}|     THE WHOLE TRUTH|          {5}|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7261141",
   "metadata": {},
   "source": [
    "# Kiểmtra đơn giản dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dadad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+--------------------+----+--------------+--------------------+-------------+\n",
      "|                 _id|  amazon_product_url|              author| bestsellers_date|         description|        price|   published_date|           publisher|rank|rank_last_week|               title|weeks_on_list|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+--------------------+----+--------------+--------------------+-------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {null, 27}|{{1212883200000}}|              Bantam| {1}|           {0}|           ODD HOURS|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}|{{1212883200000}}|       Little, Brown| {2}|           {1}|            THE HOST|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|        Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}|{{1212883200000}}|        St. Martin's| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|   Patricia Cornwell|{{1211587200000}}|A Massachusetts s...|{22.95, null}|{{1212883200000}}|              Putnam| {4}|           {0}|           THE FRONT|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Chuck Palahniuk|{{1211587200000}}|An aging porn que...|{24.95, null}|{{1212883200000}}|           Doubleday| {5}|           {0}|               SNUFF|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|James Patterson a...|{{1211587200000}}|A woman finds an ...|{24.99, null}|{{1212883200000}}|       Little, Brown| {6}|           {3}|SUNDAYS AT TIFFANY’S|          {4}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       John Sandford|{{1211587200000}}|The Minneapolis d...|{26.95, null}|{{1212883200000}}|              Putnam| {7}|           {4}|        PHANTOM PREY|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       Jimmy Buffett|{{1211587200000}}|A Southern family...|{21.99, null}|{{1212883200000}}|       Little, Brown| {8}|           {6}|          SWINE NOT?|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    Elizabeth George|{{1211587200000}}|In Cornwall, tryi...|{27.95, null}|{{1212883200000}}|              Harper| {9}|           {8}|     CARELESS IN RED|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|      David Baldacci|{{1211587200000}}|An intelligence a...|{26.99, null}|{{1212883200000}}|       Grand Central|{10}|           {7}|     THE WHOLE TRUTH|          {5}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|        Troy Denning|{{1211587200000}}|The New Jedi orde...|   {null, 27}|{{1212883200000}}|  Del Rey/Ballantine|{11}|           {5}|          INVINCIBLE|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|          James Frey|{{1211587200000}}|A novel, set in L...|{26.95, null}|{{1212883200000}}|              Harper|{12}|           {9}|BRIGHT SHINY MORNING|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|         Garth Stein|{{1211587200000}}|A Lab-terrier mix...|{23.95, null}|{{1212883200000}}|              Harper|{13}|           {0}|THE ART OF RACING...|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Debbie Macomber|{{1211587200000}}|A widow who owns ...|{24.95, null}|{{1212883200000}}|                Mira|{14}|          {10}|       TWENTY WISHES|          {4}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|         Jeff Shaara|{{1211587200000}}|A novel about the...|   {null, 28}|{{1212883200000}}|          Ballantine|{15}|          {11}|      THE STEEL WAVE|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    Phillip Margolin|{{1211587200000}}|                    |    {null, 0}|{{1212883200000}}|HarperCollins Pub...|{16}|           {0}| EXECUTIVE PRIVILEGE|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       Jhumpa Lahiri|{{1211587200000}}|Stories of the an...|    {null, 0}|{{1212883200000}}|               Knopf|{17}|           {0}|  UNACCUSTOMED EARTH|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|      Joseph O'Neill|{{1211587200000}}|A Dutchman desert...|    {null, 0}|{{1212883200000}}|Knopf Publishing ...|{18}|           {0}|          NETHERLAND|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|        John Grisham|{{1211587200000}}|Political and leg...|    {null, 0}|{{1212883200000}}|Doubleday Publishing|{19}|           {0}|          THE APPEAL|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       James Rollins|{{1211587200000}}|                    |    {null, 0}|{{1212883200000}}|Random House Publ...|{20}|           {0}|INDIANA JONES AND...|          {0}|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+--------------------+----+--------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+---------------+--------------------+---------+------------------+\n",
      "|summary|  amazon_product_url|         author|         description|publisher|             title|\n",
      "+-------+--------------------+---------------+--------------------+---------+------------------+\n",
      "|  count|               10195|          10195|               10195|    10195|             10195|\n",
      "|   mean|                null|           null|                null|     null|1877.7142857142858|\n",
      "| stddev|                null|           null|                null|     null| 370.9760613506458|\n",
      "|    min|http://www.amazon...|        AJ Finn|                    |      ACE|  10TH ANNIVERSARY|\n",
      "|    max|https://www.amazo...|various authors|’Tis for the Rebe...|allantine|               ZOO|\n",
      "+-------+--------------------+---------------+--------------------+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "extended (optional) and mode (optional) should be a string and bool; however, got [<class 'int'>].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DOHAIN~1\\AppData\\Local\\Temp/ipykernel_1452/1525701361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# In các kế hoạch bao gồm vật lý và logic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mexplain\u001b[1;34m(self, extended, mode)\u001b[0m\n\u001b[0;32m    373\u001b[0m             argtypes = [\n\u001b[0;32m    374\u001b[0m                 str(type(arg)) for arg in [extended, mode] if arg is not None]\n\u001b[1;32m--> 375\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    376\u001b[0m                 \u001b[1;34m\"extended (optional) and mode (optional) should be a string \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m                 \"and bool; however, got [%s].\" % \", \".join(argtypes))\n",
      "\u001b[1;31mTypeError\u001b[0m: extended (optional) and mode (optional) should be a string and bool; however, got [<class 'int'>]."
     ]
    }
   ],
   "source": [
    "# Trả về tên cột và kiểu dữ liệu của dataframe\n",
    "dataframe.dtypes\n",
    "# Hiển thị nội dung của dataframe\n",
    "dataframe.show()\n",
    "# Trả về n hàng đầu tiên\n",
    "dataframe.head()\n",
    "# Trả về hàng đầu tiên\n",
    "dataframe.first()\n",
    "# Return first n rows\n",
    "dataframe.take(5)\n",
    "# Tính toán số liệu thống kê tóm tắt\n",
    "dataframe.describe().show()\n",
    "# Trả về các cột của dataframe\n",
    "dataframe.columns\n",
    "# Đếm số hàng trong khung dataframe\n",
    "dataframe.count()\n",
    "# Đếm số hàng riêng biệt trong khung dữ liệu\n",
    "dataframe.distinct().count()\n",
    "# In các kế hoạch bao gồm vật lý và logic\n",
    "dataframe.explain(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf1703",
   "metadata": {},
   "source": [
    "## 3. Các hàm phổ biến hữu ích"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d31d1",
   "metadata": {},
   "source": [
    "## [1] Xóa các giá trị trùng lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2be3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+----------------+----+--------------+--------------------+-------------+\n",
      "|                 _id|  amazon_product_url|              author| bestsellers_date|         description|        price|   published_date|       publisher|rank|rank_last_week|               title|weeks_on_list|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+----------------+----+--------------+--------------------+-------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Clive Cussler wit...|{{1213401600000}}|Juan Cabrillo and...|{26.95, null}|{{1214697600000}}|          Putnam| {4}|           {3}|         PLAGUE SHIP|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|      Jeffery Deaver|{{1215820800000}}|Detectives Lincol...|    {null, 0}|{{1217116800000}}|Simon & Schuster|{20}|           {0}|   THE BROKEN WINDOW|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|        Daniel Silva|{{1217030400000}}|Gabriel Allon, an...|{26.95, null}|{{1218326400000}}|          Putnam| {1}|           {0}|  THE SECRET SERVANT|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Janet Evanovich|{{1217030400000}}|Stephanie Plum an...|{27.95, null}|{{1218326400000}}|    St. Martin’s| {9}|           {7}|   FEARLESS FOURTEEN|          {6}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|          Jane Green|{{1218240000000}}|A woman’s life ch...|    {null, 0}|{{1219536000000}}|          Viking|{18}|           {0}|     THE BEACH HOUSE|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|      Brunonia Barry|{{1220054400000}}|Secrets of a fami...|{24.95, null}|{{1221350400000}}|          Morrow|{13}|          {10}|     THE LACE READER|          {5}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    David Wroblewski|{{1221264000000}}|A mute takes refu...|{25.95, null}|{{1222560000000}}|            Ecco| {9}|           {9}|THE STORY OF EDGA...|         {14}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       John Sandford|{{1225497600000}}|Virgil Flowers in...|    {null, 0}|{{1226793600000}}|          Putnam|{20}|           {0}|      HEAT LIGHTNING|          {0}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|            J D Robb|{{1226102400000}}|Lt. Eve Dallas in...|{25.95, null}|{{1227398400000}}|          Putnam| {2}|           {0}|  SALVATION IN DEATH|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|       Toni Morrison|{{1226707200000}}|In 17th-century A...|{23.95, null}|{{1228003200000}}|           Knopf| {5}|           {0}|             A MERCY|          {1}|\n",
      "+--------------------+--------------------+--------------------+-----------------+--------------------+-------------+-----------------+----------------+----+--------------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_dropdup = dataframe.dropDuplicates()\n",
    "dataframe_dropdup.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f8f17",
   "metadata": {},
   "source": [
    "## [2] Phép toán 'Select'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c77c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              author|\n",
      "+--------------------+\n",
      "|       Dean R Koontz|\n",
      "|     Stephenie Meyer|\n",
      "|        Emily Giffin|\n",
      "|   Patricia Cornwell|\n",
      "|     Chuck Palahniuk|\n",
      "|James Patterson a...|\n",
      "|       John Sandford|\n",
      "|       Jimmy Buffett|\n",
      "|    Elizabeth George|\n",
      "|      David Baldacci|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+--------------------+----+-------------+\n",
      "|              author|               title|rank|        price|\n",
      "+--------------------+--------------------+----+-------------+\n",
      "|       Dean R Koontz|           ODD HOURS| {1}|   {null, 27}|\n",
      "|     Stephenie Meyer|            THE HOST| {2}|{25.99, null}|\n",
      "|        Emily Giffin|LOVE THE ONE YOU'...| {3}|{24.95, null}|\n",
      "|   Patricia Cornwell|           THE FRONT| {4}|{22.95, null}|\n",
      "|     Chuck Palahniuk|               SNUFF| {5}|{24.95, null}|\n",
      "|James Patterson a...|SUNDAYS AT TIFFANY’S| {6}|{24.99, null}|\n",
      "|       John Sandford|        PHANTOM PREY| {7}|{26.95, null}|\n",
      "|       Jimmy Buffett|          SWINE NOT?| {8}|{21.99, null}|\n",
      "|    Elizabeth George|     CARELESS IN RED| {9}|{27.95, null}|\n",
      "|      David Baldacci|     THE WHOLE TRUTH|{10}|{26.99, null}|\n",
      "+--------------------+--------------------+----+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hiển thị tất cả các mục trong cột tiêu đề\n",
    "dataframe.select(\"author\").show(10)\n",
    "#Hiển thị các cột title, author, rank, price\n",
    "dataframe.select(\"author\", \"title\", \"rank\", \"price\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d722c",
   "metadata": {},
   "source": [
    "## [3] Phép toán 'When'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04795b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------------------------------+\n",
      "|               title|CASE WHEN (NOT (title = ODD HOURS)) THEN 1 ELSE 0 END|\n",
      "+--------------------+-----------------------------------------------------+\n",
      "|           ODD HOURS|                                                    0|\n",
      "|            THE HOST|                                                    1|\n",
      "|LOVE THE ONE YOU'...|                                                    1|\n",
      "|           THE FRONT|                                                    1|\n",
      "|               SNUFF|                                                    1|\n",
      "|SUNDAYS AT TIFFANY’S|                                                    1|\n",
      "|        PHANTOM PREY|                                                    1|\n",
      "|          SWINE NOT?|                                                    1|\n",
      "|     CARELESS IN RED|                                                    1|\n",
      "|     THE WHOLE TRUTH|                                                    1|\n",
      "+--------------------+-----------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị tiêu đề và gán 0 hoặc 1 tùy thuộc vào tiêu đề\n",
    "dataframe.select(\"title\", when(dataframe.title != 'ODD HOURS', 1).otherwise(0)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c45787",
   "metadata": {},
   "source": [
    "## [4] Phép toán 'isin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e60397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+-----------------+--------------------+-------------+-----------------+------------+----+--------------+--------------------+-------------+\n",
      "|                 _id|  amazon_product_url|       author| bestsellers_date|         description|        price|   published_date|   publisher|rank|rank_last_week|               title|weeks_on_list|\n",
      "+--------------------+--------------------+-------------+-----------------+--------------------+-------------+-----------------+------------+----+--------------+--------------------+-------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...| Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}|{{1212883200000}}|St. Martin's| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|John Sandford|{{1211587200000}}|The Minneapolis d...|{26.95, null}|{{1212883200000}}|      Putnam| {7}|           {4}|        PHANTOM PREY|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...| Emily Giffin|{{1212192000000}}|A woman’s happy m...|{24.95, null}|{{1213488000000}}|St. Martin’s| {4}|           {3}|LOVE THE ONE YOU'...|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|John Sandford|{{1212192000000}}|The Minneapolis d...|{26.95, null}|{{1213488000000}}|      Putnam| {9}|           {7}|        PHANTOM PREY|          {4}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...| Emily Giffin|{{1212796800000}}|A woman’s happy m...|{24.95, null}|{{1214092800000}}|St. Martin’s| {4}|           {4}|LOVE THE ONE YOU'...|          {4}|\n",
      "+--------------------+--------------------+-------------+-----------------+--------------------+-------------+-----------------+------------+----+--------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị các hàng có tác giả được chỉ định nếu trong các tùy chọn đã cho\n",
    "dataframe [dataframe.author.isin(\"John Sandford\", \"Emily Giffin\")].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f1174",
   "metadata": {},
   "source": [
    "## [5] Phép toán 'Like'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7de48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|              author|               title|title LIKE % THE %|\n",
      "+--------------------+--------------------+------------------+\n",
      "|       Dean R Koontz|           ODD HOURS|             false|\n",
      "|     Stephenie Meyer|            THE HOST|             false|\n",
      "|        Emily Giffin|LOVE THE ONE YOU'...|              true|\n",
      "|   Patricia Cornwell|           THE FRONT|             false|\n",
      "|     Chuck Palahniuk|               SNUFF|             false|\n",
      "|James Patterson a...|SUNDAYS AT TIFFANY’S|             false|\n",
      "|       John Sandford|        PHANTOM PREY|             false|\n",
      "|       Jimmy Buffett|          SWINE NOT?|             false|\n",
      "|    Elizabeth George|     CARELESS IN RED|             false|\n",
      "|      David Baldacci|     THE WHOLE TRUTH|             false|\n",
      "|        Troy Denning|          INVINCIBLE|             false|\n",
      "|          James Frey|BRIGHT SHINY MORNING|             false|\n",
      "|         Garth Stein|THE ART OF RACING...|              true|\n",
      "|     Debbie Macomber|       TWENTY WISHES|             false|\n",
      "|         Jeff Shaara|      THE STEEL WAVE|             false|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị tác giả và tiêu đề là TRUE nếu tiêu đề có từ \" THE \" trong tiêu đề\n",
    "dataframe.select(\"author\", \"title\", dataframe.title.like(\"% THE %\")).show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641081d5",
   "metadata": {},
   "source": [
    "## [6] Phép toán 'Startswith' — 'Endswith'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e83b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------------------+\n",
      "|           author|               title|startswith(title, THE)|\n",
      "+-----------------+--------------------+----------------------+\n",
      "|    Dean R Koontz|           ODD HOURS|                 false|\n",
      "|  Stephenie Meyer|            THE HOST|                  true|\n",
      "|     Emily Giffin|LOVE THE ONE YOU'...|                 false|\n",
      "|Patricia Cornwell|           THE FRONT|                  true|\n",
      "|  Chuck Palahniuk|               SNUFF|                 false|\n",
      "+-----------------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+--------------------+-------------------+\n",
      "|           author|               title|endswith(title, NT)|\n",
      "+-----------------+--------------------+-------------------+\n",
      "|    Dean R Koontz|           ODD HOURS|              false|\n",
      "|  Stephenie Meyer|            THE HOST|              false|\n",
      "|     Emily Giffin|LOVE THE ONE YOU'...|              false|\n",
      "|Patricia Cornwell|           THE FRONT|               true|\n",
      "|  Chuck Palahniuk|               SNUFF|              false|\n",
      "+-----------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(\"author\", \"title\", dataframe.title.startswith(\"THE\")).show(5)\n",
    "dataframe.select(\"author\", \"title\", dataframe.title.endswith(\"NT\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb3797",
   "metadata": {},
   "source": [
    "## [7] Phép toán 'Substring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9255e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|title|\n",
      "+-----+\n",
      "|  Dea|\n",
      "|  Ste|\n",
      "|  Emi|\n",
      "|  Pat|\n",
      "|  Chu|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|an R K|\n",
      "|epheni|\n",
      "|ily Gi|\n",
      "|tricia|\n",
      "|uck Pa|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|Dean R|\n",
      "|Stephe|\n",
      "|Emily |\n",
      "|Patric|\n",
      "|Chuck |\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(dataframe.author.substr(1, 3).alias(\"title\")).show(5)\n",
    "dataframe.select(dataframe.author.substr(3, 6).alias(\"title\")).show(5)\n",
    "dataframe.select(dataframe.author.substr(1, 6).alias(\"title\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b92af",
   "metadata": {},
   "source": [
    "## [8] Thêmcột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e607cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<$oid:string>, amazon_product_url: string, author: string, bestsellers_date: struct<$date:struct<$numberLong:string>>, description: string, price: struct<$numberDouble:string,$numberInt:string>, published_date: struct<$date:struct<$numberLong:string>>, publisher: string, rank: struct<$numberInt:string>, rank_last_week: struct<$numberInt:string>, title: string, weeks_on_list: struct<$numberInt:string>, new_column: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Lit() được yêu cầu trong khi chúng tôi đang tạo các cột có giá trị chính xác.\n",
    "dataframe = dataframe.withColumn('new_column', F.lit('This is a new column'))\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabb0f1",
   "metadata": {},
   "source": [
    "## [9] Cập nhậtcột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a27e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|                 _id|                 URL|           author| bestsellers_date|         description|        price|   published_date|    publisher|rank|rank_last_week|               title|weeks_on_list|          new_column|\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {null, 27}|{{1212883200000}}|       Bantam| {1}|           {0}|           ODD HOURS|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}|{{1212883200000}}|Little, Brown| {2}|           {1}|            THE HOST|          {3}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}|{{1212883200000}}| St. Martin's| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Patricia Cornwell|{{1211587200000}}|A Massachusetts s...|{22.95, null}|{{1212883200000}}|       Putnam| {4}|           {0}|           THE FRONT|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Chuck Palahniuk|{{1211587200000}}|An aging porn que...|{24.95, null}|{{1212883200000}}|    Doubleday| {5}|           {0}|               SNUFF|          {1}|This is a new column|\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cập nhật cột 'amazon_product_url' bằng 'URL'\n",
    "dataframe = dataframe.withColumnRenamed('amazon_product_url', 'URL')\n",
    "dataframe.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1f109",
   "metadata": {},
   "source": [
    "## [10] Loại bỏ cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "048998f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|                 _id|                 URL|           author| bestsellers_date|         description|        price|rank|rank_last_week|               title|weeks_on_list|          new_column|\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {null, 27}| {1}|           {0}|           ODD HOURS|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}| {2}|           {1}|            THE HOST|          {3}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Patricia Cornwell|{{1211587200000}}|A Massachusetts s...|{22.95, null}| {4}|           {0}|           THE FRONT|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Chuck Palahniuk|{{1211587200000}}|An aging porn que...|{24.95, null}| {5}|           {0}|               SNUFF|          {1}|This is a new column|\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|                 _id|                 URL|           author| bestsellers_date|         description|        price|rank|rank_last_week|               title|weeks_on_list|          new_column|\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|    Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {null, 27}| {1}|           {0}|           ODD HOURS|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}| {2}|           {1}|            THE HOST|          {3}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|     Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Patricia Cornwell|{{1211587200000}}|A Massachusetts s...|{22.95, null}| {4}|           {0}|           THE FRONT|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Chuck Palahniuk|{{1211587200000}}|An aging porn que...|{24.95, null}| {5}|           {0}|               SNUFF|          {1}|This is a new column|\n",
      "+--------------------+--------------------+-----------------+-----------------+--------------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "dataframe_remove = dataframe.drop(\"publisher\", \"published_date\").show(5)\n",
    "# 2.\n",
    "dataframe_remove2 = dataframe.drop(dataframe.publisher).drop(dataframe.published_date).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbc757",
   "metadata": {},
   "source": [
    "## [11] Phép toán 'GroupBy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827974b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              author|count|\n",
      "+--------------------+-----+\n",
      "|          James Frey|    2|\n",
      "|    Elin Hilderbrand|   58|\n",
      "|   Sharon Kay Penman|    2|\n",
      "|         Kate Jacobs|    3|\n",
      "|       Karen Robards|    6|\n",
      "|     Gary Shteyngart|    3|\n",
      "|         Lisa Genova|    7|\n",
      "|James Patterson a...|   30|\n",
      "|         Ruth Reichl|    3|\n",
      "|    Orson Scott Card|    3|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nhóm theo tác giả, đếm sách của các tác giả trong nhóm\n",
    "dataframe.groupBy(\"author\").count().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dee898",
   "metadata": {},
   "source": [
    "## [12] Phép toán 'Filter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f381d969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------+-------------+--------------------+\n",
      "|                 _id|                 URL|         author| bestsellers_date|         description|        price|   published_date|    publisher|rank|rank_last_week|   title|weeks_on_list|          new_column|\n",
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------+-------------+--------------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}|{{1212883200000}}|Little, Brown| {2}|           {1}|THE HOST|          {3}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1212192000000}}|Aliens have taken...|{25.99, null}|{{1213488000000}}|Little, Brown| {2}|           {2}|THE HOST|          {4}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1212796800000}}|Aliens have taken...|{25.99, null}|{{1214092800000}}|Little, Brown| {2}|           {2}|THE HOST|          {5}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1213401600000}}|Aliens have taken...|{25.99, null}|{{1214697600000}}|Little, Brown| {3}|           {2}|THE HOST|          {6}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1214006400000}}|Aliens have taken...|{25.99, null}|{{1215302400000}}|Little, Brown| {3}|           {3}|THE HOST|          {7}|This is a new column|\n",
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lọc các mục tiêu đề\n",
    "# Chỉ giữ các bản ghi có giá trị 'THE HOST'\n",
    "dataframe.filter(dataframe[\"title\"] == 'THE HOST').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e708569",
   "metadata": {},
   "source": [
    "## [13] Xử lý các giá trị bị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c238af25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<$oid:string>, URL: string, author: string, bestsellers_date: struct<$date:struct<$numberLong:string>>, description: string, price: struct<$numberDouble:string,$numberInt:string>, published_date: struct<$date:struct<$numberLong:string>>, publisher: string, rank: struct<$numberInt:string>, rank_last_week: struct<$numberInt:string>, title: string, weeks_on_list: struct<$numberInt:string>, new_column: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thay thế giá trị null\n",
    "dataframe.na.fill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611cfab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<$oid:string>, URL: string, author: string, bestsellers_date: struct<$date:struct<$numberLong:string>>, description: string, price: struct<$numberDouble:string,$numberInt:string>, published_date: struct<$date:struct<$numberLong:string>>, publisher: string, rank: struct<$numberInt:string>, rank_last_week: struct<$numberInt:string>, title: string, weeks_on_list: struct<$numberInt:string>, new_column: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trả về các hàng giới hạn khung dữ liệu mới có giá trị nulldataframe.na.drop()\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0d4cf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<$oid:string>, URL: string, author: string, bestsellers_date: struct<$date:struct<$numberLong:string>>, description: string, price: struct<$numberDouble:string,$numberInt:string>, published_date: struct<$date:struct<$numberLong:string>>, publisher: string, rank: struct<$numberInt:string>, rank_last_week: struct<$numberInt:string>, title: string, weeks_on_list: struct<$numberInt:string>, new_column: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trả về khung dữ liệu mới thay thế một giá trị bằng một giá trị khác\n",
    "dataframe.na.replace(5, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb6231",
   "metadata": {},
   "source": [
    "## [14] phân vùng lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc0a94f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe với 10 phân vùng\n",
    "dataframe.repartition(10).rdd.getNumPartitions()\n",
    "# Dataframe với 1 phân vùng\n",
    "dataframe.coalesce(1).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c6ec9",
   "metadata": {},
   "source": [
    "## [15] Chạy cáclệnh SQLtrong Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5399978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|                 _id|                 URL|         author| bestsellers_date|         description|        price|   published_date|    publisher|rank|rank_last_week|               title|weeks_on_list|          new_column|\n",
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {null, 27}|{{1212883200000}}|       Bantam| {1}|           {0}|           ODD HOURS|          {1}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, null}|{{1212883200000}}|Little, Brown| {2}|           {1}|            THE HOST|          {3}|This is a new column|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|   Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, null}|{{1212883200000}}| St. Martin's| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|This is a new column|\n",
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+--------------------+-------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "ename": "ParseException",
     "evalue": "\nmismatched input '\"' expecting {<EOF>, ';'}(line 2, pos 429)\n\n== SQL ==\nSELECT CASE WHEN description LIKE '%love%' THEN 'Love_Theme'\n            WHEN description LIKE '%hate%' THEN 'Hate_Theme'             WHEN description LIKE '%happy%' THEN 'Happiness_Theme'             WHEN description LIKE '%anger%' THEN 'Anger_Theme'             WHEN description LIKE '%horror%' THEN 'Horror_Theme'             WHEN description LIKE '%death%' THEN 'Criminal_Theme'             WHEN description LIKE '%detective%' THEN 'Mystery_Theme' ELSE 'Other_Themes' END Themes from df\").groupBy('Themes').count().show()\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DOHAIN~1\\AppData\\Local\\Temp/ipykernel_1452/3205876381.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregisterTempTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select * from df\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m sc.sql(\"\"\"SELECT CASE WHEN description LIKE '%love%' THEN 'Love_Theme'\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mWHEN\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0mLIKE\u001b[0m \u001b[1;34m'%hate%'\u001b[0m \u001b[0mTHEN\u001b[0m \u001b[1;34m'Hate_Theme'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mWHEN\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0mLIKE\u001b[0m \u001b[1;34m'%happy%'\u001b[0m \u001b[0mTHEN\u001b[0m \u001b[1;34m'Happiness_Theme'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36msql\u001b[1;34m(self, sqlQuery)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \"\"\"\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark\\spark-3.2.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParseException\u001b[0m: \nmismatched input '\"' expecting {<EOF>, ';'}(line 2, pos 429)\n\n== SQL ==\nSELECT CASE WHEN description LIKE '%love%' THEN 'Love_Theme'\n            WHEN description LIKE '%hate%' THEN 'Hate_Theme'             WHEN description LIKE '%happy%' THEN 'Happiness_Theme'             WHEN description LIKE '%anger%' THEN 'Anger_Theme'             WHEN description LIKE '%horror%' THEN 'Horror_Theme'             WHEN description LIKE '%death%' THEN 'Criminal_Theme'             WHEN description LIKE '%detective%' THEN 'Mystery_Theme' ELSE 'Other_Themes' END Themes from df\").groupBy('Themes').count().show()\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------^^^\n"
     ]
    }
   ],
   "source": [
    "# Đăng ký bảng\n",
    "dataframe.registerTempTable(\"df\")\n",
    "sc.sql(\"select * from df\").show(3)\n",
    "sc.sql(\"\"\"SELECT CASE WHEN description LIKE '%love%' THEN 'Love_Theme'\n",
    "            WHEN description LIKE '%hate%' THEN 'Hate_Theme' \\\n",
    "            WHEN description LIKE '%happy%' THEN 'Happiness_Theme' \\\n",
    "            WHEN description LIKE '%anger%' THEN 'Anger_Theme' \\\n",
    "            WHEN description LIKE '%horror%' THEN 'Horror_Theme' \\\n",
    "            WHEN description LIKE '%death%' THEN 'Criminal_Theme' \\\n",
    "            WHEN description LIKE '%detective%' THEN 'Mystery_Theme' ELSE 'Other_Themes' END Themes from df\").groupBy('Themes').count().show()\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d0e3d",
   "metadata": {},
   "source": [
    "## [16] Xuất dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d236182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  Nested StructType not supported in conversion to Arrow\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o126.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 44) (MSI executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:410)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3538)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3535)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DOHAIN~1\\AppData\\Local\\Temp/ipykernel_1452/2474906313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoJSON\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Lấy nội dung của df dưới dạng Pandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mcolumn_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \"\"\"\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark\\spark-3.2.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark/spark/spark-3.2.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark\\spark-3.2.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o126.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 43.0 failed 1 times, most recent failure: Lost task 0.0 in stage 43.0 (TID 44) (MSI executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:410)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3538)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3535)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi khung dữ liệu thành RDD\n",
    "rdd_convert = dataframe.rdd\n",
    "# Chuyển đổi khung dữ liệu thành RDD của chuỗi\n",
    "dataframe.toJSON().first()\n",
    "# Lấy nội dung của df dưới dạng Pandas\n",
    "dataframe.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458699f7",
   "metadata": {},
   "source": [
    "## [17] Viết và lưu vào tệp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a328be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết và lưu tệp ở định dạng .parquet\n",
    "dataframe.select(\"author\", \"title\", \"rank\", \"description\") \\\n",
    ".write \\\n",
    ".save(\"Rankings_Descriptions.parquet\")\n",
    "# Viết và lưu tệp ở định dạng .json\n",
    "dataframe.select(\"author\", \"title\") \\\n",
    ".write \\\n",
    ".save(\"Authors_Titles.json\",format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe126c",
   "metadata": {},
   "source": [
    "## [18] Kết thúc phiên Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
