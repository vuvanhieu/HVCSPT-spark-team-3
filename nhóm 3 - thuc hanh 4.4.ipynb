{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bai 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nhập lớp SparkSession từ mô-đun pyspark.sql\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# # tạo một đối tượng SparkSession\n",
    "# spark = SparkSession.builder.appName(\"CreateDataFrame\").getOrCreate()\n",
    "\n",
    "# # tạo một danh sách từ điển chứa dữ liệu\n",
    "# data = [{'id': 1, 'age': 25, 'gender': 'male', 'song': 'Shape of You', 'genres': 'Pop'},\n",
    "#         {'id': 2, 'age': 30, 'gender': 'female', 'song': 'Despacito', 'genres': 'Latin'},\n",
    "#         {'id': 3, 'age': 20, 'gender': 'male', 'song': 'Uptown Funk', 'genres': 'Funk'},\n",
    "#         {'id': 4, 'age': 35, 'gender': 'female', 'song': 'Shallow', 'genres': 'Pop'},\n",
    "#         {'id': 5, 'age': 28, 'gender': 'male', 'song': 'Perfect', 'genres': 'Pop'},\n",
    "#         {'id': 6, 'age': 22, 'gender': 'female', 'song': 'Roar', 'genres': 'Pop'}]\n",
    "\n",
    "# # tạo một DataFrame từ danh sách từ điển \n",
    "# df = spark.createDataFrame(data)\n",
    "\n",
    "# # hiển thị DataFrame\n",
    "# df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# Data = [[1,20,\"Male\",\"Nguoi ay\",\"Nhac tre\"],\n",
    "#         [2,32,\"Female\",\"Don't Coi\",\"Nhac rap\"],\n",
    "#         [3,21,\"Male\",\"Chim Sau\",\"Nhac rap\"],\n",
    "#         [4,20,'Male','Lay chong som lam gi','Nhac tre'],\n",
    "#         [5,19,\"Male\",'Ong troi lam toi anh chua','Nhac tre'],\n",
    "#         [6,20,\"Male\",'Hen em kiep sau','Nhac tre'],\n",
    "#         [7,23,'Female','Khi ma','Nhac rap'],\n",
    "#         [8,31,'Male','Tri ky','Nhac tre'],\n",
    "#         [9,20,'Female','Them bao nhieu lau','Nhac rap'],\n",
    "#         [10,23,'Male','Thi mau','Nhac tre']]\n",
    "# df_new = pd.DataFrame(Data, columns = [\"id\",\"tuoi\",'sex',\"ten nhac\",\"loai nhac\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ghi tep\n",
    "# df_new.to_csv(\"C:/Users/Admin/Documents/Tài liệu/Tài liệu Apache Spark/Tài liệu CODE SPARK/4.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------------+\n",
      "|age|gender|genres| id|          song|\n",
      "+---+------+------+---+--------------+\n",
      "| 25|  male|   Pop|  1|  Shape of You|\n",
      "| 30|female| Latin|  2|     Despacito|\n",
      "| 20|  male|  Funk|  3|   Uptown Funk|\n",
      "| 35|female|   Pop|  4|       Shallow|\n",
      "| 28|  male|   Pop|  5|       Perfect|\n",
      "| 22|female|   Pop|  6|          Roar|\n",
      "| 23|female|  Jazz|  7|Never giver up|\n",
      "| 24|female|   Pop|  8|         Sugar|\n",
      "| 32|  male|   Pop|  9|          Maps|\n",
      "| 19|female|   Pop| 10|       Pip pop|\n",
      "| 20|female|   Pop| 11|       Pip pop|\n",
      "+---+------+------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('rc').getOrCreate()\n",
    "#thu vien truy van\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# tạo một đối tượng SparkSession\n",
    "spark = SparkSession.builder.appName(\"CreateDataFrame\").getOrCreate()\n",
    "\n",
    "# tạo một danh sách từ điển chứa dữ liệu\n",
    "data = [{'id': 1, 'age': 25, 'gender': 'male', 'song': 'Shape of You', 'genres': 'Pop'},\n",
    "        {'id': 2, 'age': 30, 'gender': 'female', 'song': 'Despacito', 'genres': 'Latin'},\n",
    "        {'id': 3, 'age': 20, 'gender': 'male', 'song': 'Uptown Funk', 'genres': 'Funk'},\n",
    "        {'id': 4, 'age': 35, 'gender': 'female', 'song': 'Shallow', 'genres': 'Pop'},\n",
    "        {'id': 5, 'age': 28, 'gender': 'male', 'song': 'Perfect', 'genres': 'Pop'},\n",
    "        {'id': 6, 'age': 22, 'gender': 'female', 'song': 'Roar', 'genres': 'Pop'},\n",
    "        {'id': 7, 'age': 23, 'gender': 'female', 'song': 'Never giver up', 'genres': 'Jazz'},\n",
    "        {'id': 8, 'age': 24, 'gender': 'female', 'song': 'Sugar', 'genres': 'Pop'},\n",
    "        {'id': 9, 'age': 32, 'gender': 'male', 'song': 'Maps', 'genres': 'Pop'},\n",
    "        {'id': 10, 'age': 19, 'gender': 'female', 'song': 'Pip pop', 'genres': 'Pop'},\n",
    "        {'id': 11, 'age': 20, 'gender': 'female', 'song': 'Pip pop', 'genres': 'Pop'}]\n",
    "\n",
    "# tạo một DataFrame từ danh sách từ điển \n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# hiển thị DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[age: bigint, gender: string, genres: string, id: bigint, song: string]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xem kich thuoc du lieu\n",
    "print((df.count(),len(df.columns)))\n",
    "\n",
    "#xem cac cot du lieu \n",
    "df.printSchema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bai 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|song          |count|\n",
      "+--------------+-----+\n",
      "|Pip pop       |2    |\n",
      "|Shape of You  |1    |\n",
      "|Roar          |1    |\n",
      "|Despacito     |1    |\n",
      "|Never giver up|1    |\n",
      "|Uptown Funk   |1    |\n",
      "|Perfect       |1    |\n",
      "|Shallow       |1    |\n",
      "|Sugar         |1    |\n",
      "|Maps          |1    |\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.groupBy('song').count().orderBy('count',ascending=False).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------------+----------+--------+----------+\n",
      "|age|gender|genres| id|          song|gender_Num|song_Num|genres_Num|\n",
      "+---+------+------+---+--------------+----------+--------+----------+\n",
      "| 25|  male|   Pop|  1|  Shape of You|       1.0|     7.0|       0.0|\n",
      "| 30|female| Latin|  2|     Despacito|       0.0|     1.0|       3.0|\n",
      "| 20|  male|  Funk|  3|   Uptown Funk|       1.0|     9.0|       1.0|\n",
      "| 35|female|   Pop|  4|       Shallow|       0.0|     6.0|       0.0|\n",
      "| 28|  male|   Pop|  5|       Perfect|       1.0|     4.0|       0.0|\n",
      "| 22|female|   Pop|  6|          Roar|       0.0|     5.0|       0.0|\n",
      "| 23|female|  Jazz|  7|Never giver up|       0.0|     3.0|       2.0|\n",
      "| 24|female|   Pop|  8|         Sugar|       0.0|     8.0|       0.0|\n",
      "| 32|  male|   Pop|  9|          Maps|       1.0|     2.0|       0.0|\n",
      "| 19|female|   Pop| 10|       Pip pop|       0.0|     0.0|       0.0|\n",
      "+---+------+------+---+--------------+----------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# - chuyen du lieu tu text sang so va bo sung them cot\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "gender_indexer = StringIndexer(inputCol='gender',outputCol = 'gender_Num').fit(df)\n",
    "df = gender_indexer.transform(df)\n",
    "\n",
    "\n",
    "# - chuyen du lieu tu text sang so va bo sung them cot\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "song_indexer = StringIndexer(inputCol='song',outputCol = 'song_Num').fit(df)\n",
    "df = song_indexer.transform(df)\n",
    "\n",
    "# - chuyen du lieu tu text sang so va bo sung them cot\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "genres_indexer = StringIndexer(inputCol='genres',outputCol = 'genres_Num').fit(df)\n",
    "df = genres_indexer.transform(df)\n",
    "\n",
    "#hien thi 1- dong cua bang du lieu moi\n",
    "df.show(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|genres_Num|count|\n",
      "+----------+-----+\n",
      "|       0.0|    8|\n",
      "|       3.0|    1|\n",
      "|       2.0|    1|\n",
      "|       1.0|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nhom tieu de nhac duoc danh gia theo thu tu giam dan. Hien thi xem la 10 dong\n",
    "df.groupBy('genres_Num').count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.1 chia du lieu cua bang indexed vao hai tap train va test\n",
    "#chia theo ti le 75% va 25%\n",
    "train,test=df.randomSplit([0.8,0.2])\n",
    "\n",
    "#xem kich thuoc tap train va test\n",
    "train.count(),test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "#khai bao bien doi tuong ALS\n",
    "recommendation = ALS(maxIter=10,\n",
    "                     regParam=0.01,\n",
    "                     userCol='id',\n",
    "                     itemCol='song_Num',\n",
    "                     ratingCol='genres_Num',\n",
    "                     nonnegative=True,\n",
    "                     coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#huan luyen mo hinh\n",
    "recommendation_model = recommendation.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#du bao ten tap kiem tra\n",
    "predicted_ratings = recommendation_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- gender_Num: double (nullable = false)\n",
      " |-- song_Num: double (nullable = false)\n",
      " |-- genres_Num: double (nullable = false)\n",
      " |-- prediction: float (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Nothing has been added to this summarizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Documents\\Tài liệu\\Tài liệu Apache Spark\\Tài liệu CODE SPARK\\thuc hanh 4.4.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m predictions \u001b[39m=\u001b[39m recommendation_model\u001b[39m.\u001b[39mtransform(test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#danh gia độ do rmse trên kết quả dự báo\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m rmse \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39;49mevaluate(predictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#in ket quả độ do rmse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(rmse)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\pyspark\\ml\\evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_evaluate(dataset)\n\u001b[0;32m    110\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate(dataset)\n\u001b[0;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\pyspark\\ml\\evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mevaluate(dataset\u001b[39m.\u001b[39;49m_jdf)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\pyspark\\sql\\utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Nothing has been added to this summarizer."
     ]
    }
   ],
   "source": [
    "\n",
    "#buoc6.1 tai thu vien danh gia'\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#buoc6.2 danh gia ket qua theo chi so hoi quy\n",
    "\n",
    "#khai bao bien doi tuong danh gia RegressionEvaluator, su dung độ do rmse\n",
    "evaluator= RegressionEvaluator(metricName='rmse',predictionCol='prediction',labelCol='genres_Num')\n",
    "\n",
    "#du bao tren du lieu test su dung mo hinh da duoc xay dung truoc\n",
    "predictions = recommendation_model.transform(test)\n",
    "\n",
    "#danh gia độ do rmse trên kết quả dự báo\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "#in ket quả độ do rmse\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_genres(id,n):\n",
    "    #7.1 nhom the loai nhac theo cột tiêu đề của bảng đã chuyển đổi\n",
    "    unique_genres = df.select('genres_Num').distinct()\n",
    "\n",
    "    #7.2 dem so nhac khac nhau\n",
    "    unique_genres.count()\n",
    "\n",
    "    #7.3 tao bang tam: ga'n 1 the loai nhac la 'a' voi danh sach nhac phan biet\n",
    "    a = unique_genres.alias('a')\n",
    "\n",
    "    #7.4 chon nguoi dung tuy y'\n",
    "    id = id\n",
    "\n",
    "    #7.5 tao 1 bang chua nhung the loai ma nguoi dung  da xem\n",
    "    listen_genres = df.filter(df['id'] == id).select('genres_Num').distinct()\n",
    "\n",
    "    #7.6 dem so phim da danh gia boi nguoi dung do\n",
    "    listen_genres.count()\n",
    "\n",
    "    #7.7 tao bang tam: gan ten 'b' cho nhung nhac da xem\n",
    "    b = listen_genres.alias('b')\n",
    "\n",
    "    #7.8 ket noi hai bang\n",
    "    total_genres = a.join(b, a.genres_Num == b.genres_Num,how='left')\n",
    "\n",
    "    #7.9 hien thi 10 ket qua cua bang ket noi\n",
    "    total_genres.show(10,False)\n",
    "\n",
    "    #7.10 lua chon nhac ma nguoi dung do chua nghe de danh gia hoac nghe\n",
    "    remaining_genres = total_genres.where(col('b.genres_Num').isNull()).select(a.genres_Num).distinct()\n",
    "\n",
    "    #7.11 phim ma nguoi dung do chua danh gia\n",
    "    remaining_genres.count()\n",
    "\n",
    "    #7.12 them cot moi 'user_Id' de lay nhung phim chua xem\n",
    "    remaining_genres = remaining_genres.withColumn('id',lit(int(id)))\n",
    "\n",
    "    #7.13 hien thi 10 ket qua phim chua xem\n",
    "    remaining_genres.show(10,False)\n",
    "\n",
    "    #7.14 goi y phim cho nguoi dung su dung thu vien hoc may ALS\n",
    "    recommendations= recommendation_model.transform(remaining_genres).orderBy('prediction',ascending=False)\n",
    "\n",
    "    #7.15 hien thi 5 ket qua\n",
    "    recommendations.show(5,False)\n",
    "\n",
    "    #7.16 chuyen ten phim tu gia tri so sang van ban\n",
    "    #khai bao bien doi tuong IndexToString\n",
    "    genres_title = IndexToString(inputCol='genres_Num',outputCol='genres',labels = model.labels)\n",
    "\n",
    "    #chuyen doi ten phim sang van ban\n",
    "    final_recommendations = genres_title.transform(recommendations)\n",
    "\n",
    "    #hien thi 10 ket qua\n",
    "    final_recommendations.show(5,False)\n",
    "    \n",
    "    #tra lai goi y cho nguoi dung hoat dong\n",
    "    return final_recommendations.show(n,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|genres_Num|genres_Num|\n",
      "+----------+----------+\n",
      "|0.0       |null      |\n",
      "|1.0       |1.0       |\n",
      "|3.0       |null      |\n",
      "|2.0       |null      |\n",
      "+----------+----------+\n",
      "\n",
      "+----------+---+\n",
      "|genres_Num|id |\n",
      "+----------+---+\n",
      "|0.0       |3  |\n",
      "|3.0       |3  |\n",
      "|2.0       |3  |\n",
      "+----------+---+\n",
      "\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "song_Num does not exist. Available: genres_Num, id",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Documents\\Tài liệu\\Tài liệu Apache Spark\\Tài liệu CODE SPARK\\thuc hanh 4.4.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m top_genres(\u001b[39m3\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Admin\\Documents\\Tài liệu\\Tài liệu Apache Spark\\Tài liệu CODE SPARK\\thuc hanh 4.4.ipynb Cell 18\u001b[0m in \u001b[0;36mtop_genres\u001b[1;34m(id, n)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X22sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m remaining_genres\u001b[39m.\u001b[39mshow(\u001b[39m10\u001b[39m,\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X22sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#7.14 goi y phim cho nguoi dung su dung thu vien hoc may ALS\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X22sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m recommendations\u001b[39m=\u001b[39m recommendation_model\u001b[39m.\u001b[39;49mtransform(remaining_genres)\u001b[39m.\u001b[39morderBy(\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m,ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X22sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m#7.15 hien thi 5 ket qua\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/T%C3%A0i%20li%E1%BB%87u/T%C3%A0i%20li%E1%BB%87u%20Apache%20Spark/T%C3%A0i%20li%E1%BB%87u%20CODE%20SPARK/thuc%20hanh%204.4.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m recommendations\u001b[39m.\u001b[39mshow(\u001b[39m5\u001b[39m,\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\pyspark\\ml\\base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_transform(dataset)\n\u001b[0;32m    261\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(dataset)\n\u001b[0;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\pyspark\\ml\\wrapper.py:400\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 400\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mtransform(dataset\u001b[39m.\u001b[39;49m_jdf), dataset\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mC:\\spark\\spark-3.3.1-bin-hadoop2\\python\\pyspark\\sql\\utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: song_Num does not exist. Available: genres_Num, id"
     ]
    }
   ],
   "source": [
    "top_genres(3,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
